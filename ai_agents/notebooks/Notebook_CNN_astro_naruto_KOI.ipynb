{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jeA3H9PC4Mb",
        "outputId": "e39a8445-406d-432a-da4a-053470f84f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Avant filtrage: (array([0, 1, 2]), array([3016,  971, 2299]))\n",
            "Après filtrage: {np.int64(0): np.int64(3016), np.int64(1): np.int64(2299)}\n",
            "Global: (5315, 2001, 1)  Local: (5315, 201, 1)  Labels: (5315,)\n",
            "Train: (4252, 2001, 1)  Val: (531, 2001, 1)  Test: (532, 2001, 1)\n",
            "Epoch 1/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.5332 - loss: 2.9324 - val_accuracy: 0.5669 - val_loss: 0.6879\n",
            "Epoch 2/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5683 - loss: 1.5928 - val_accuracy: 0.5669 - val_loss: 0.6886\n",
            "Epoch 3/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5747 - loss: 1.2248 - val_accuracy: 0.5669 - val_loss: 0.6899\n",
            "Epoch 4/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6095 - loss: 1.0415 - val_accuracy: 0.5669 - val_loss: 0.6909\n",
            "Epoch 5/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5765 - loss: 1.0114 - val_accuracy: 0.5669 - val_loss: 0.6904\n",
            "Epoch 6/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6087 - loss: 0.9167 - val_accuracy: 0.5028 - val_loss: 0.6914\n",
            "Epoch 7/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5963 - loss: 0.7999 - val_accuracy: 0.5009 - val_loss: 0.6900\n",
            "Epoch 8/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6122 - loss: 0.7276 - val_accuracy: 0.5141 - val_loss: 0.6862\n",
            "Epoch 9/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6146 - loss: 0.6809 - val_accuracy: 0.5405 - val_loss: 0.6779\n",
            "Epoch 10/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6168 - loss: 0.6589 - val_accuracy: 0.5593 - val_loss: 0.6673\n",
            "Epoch 11/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6179 - loss: 0.6395 - val_accuracy: 0.5725 - val_loss: 0.6559\n",
            "Epoch 12/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6382 - loss: 0.5996 - val_accuracy: 0.5706 - val_loss: 0.6447\n",
            "Epoch 13/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6230 - loss: 0.6164 - val_accuracy: 0.5631 - val_loss: 0.6337\n",
            "Epoch 14/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6436 - loss: 0.5918 - val_accuracy: 0.5706 - val_loss: 0.6228\n",
            "Epoch 15/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6354 - loss: 0.6020 - val_accuracy: 0.5913 - val_loss: 0.6132\n",
            "Epoch 16/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6273 - loss: 0.6261 - val_accuracy: 0.5763 - val_loss: 0.6065\n",
            "Epoch 17/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6189 - loss: 0.6471 - val_accuracy: 0.5970 - val_loss: 0.6065\n",
            "Epoch 18/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6420 - loss: 0.5915 - val_accuracy: 0.5932 - val_loss: 0.6088\n",
            "Epoch 19/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6586 - loss: 0.5826 - val_accuracy: 0.5989 - val_loss: 0.5966\n",
            "Epoch 20/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6475 - loss: 0.5799 - val_accuracy: 0.6026 - val_loss: 0.5871\n",
            "Epoch 21/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6494 - loss: 0.5721 - val_accuracy: 0.6026 - val_loss: 0.5927\n",
            "Epoch 22/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6668 - loss: 0.5702 - val_accuracy: 0.5913 - val_loss: 0.5949\n",
            "Epoch 23/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6721 - loss: 0.5611 - val_accuracy: 0.5970 - val_loss: 0.5967\n",
            "Epoch 24/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6497 - loss: 0.5790 - val_accuracy: 0.5913 - val_loss: 0.5893\n",
            "Epoch 25/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6615 - loss: 0.5568 - val_accuracy: 0.6271 - val_loss: 0.5830\n",
            "Epoch 26/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6646 - loss: 0.5675 - val_accuracy: 0.5838 - val_loss: 0.5874\n",
            "Epoch 27/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6808 - loss: 0.5565 - val_accuracy: 0.5725 - val_loss: 0.5949\n",
            "Epoch 28/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6768 - loss: 0.5549 - val_accuracy: 0.6064 - val_loss: 0.5882\n",
            "Epoch 29/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6790 - loss: 0.5434 - val_accuracy: 0.6252 - val_loss: 0.5745\n",
            "Epoch 30/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6826 - loss: 0.5483 - val_accuracy: 0.6064 - val_loss: 0.5936\n",
            "Epoch 31/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6879 - loss: 0.5398 - val_accuracy: 0.6083 - val_loss: 0.5867\n",
            "Epoch 32/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6753 - loss: 0.5433 - val_accuracy: 0.6158 - val_loss: 0.5756\n",
            "Epoch 33/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6711 - loss: 0.5526 - val_accuracy: 0.6271 - val_loss: 0.5695\n",
            "Epoch 34/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6955 - loss: 0.5421 - val_accuracy: 0.6271 - val_loss: 0.5696\n",
            "Epoch 35/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6749 - loss: 0.5436 - val_accuracy: 0.6309 - val_loss: 0.5689\n",
            "Epoch 36/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6799 - loss: 0.5428 - val_accuracy: 0.5800 - val_loss: 0.6132\n",
            "Epoch 37/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6657 - loss: 0.5464 - val_accuracy: 0.5725 - val_loss: 0.7005\n",
            "Epoch 38/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6827 - loss: 0.5558 - val_accuracy: 0.6026 - val_loss: 0.6974\n",
            "Epoch 39/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6817 - loss: 0.5534 - val_accuracy: 0.5687 - val_loss: 0.7432\n",
            "Epoch 40/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6945 - loss: 0.5436 - val_accuracy: 0.5687 - val_loss: 0.7989\n",
            "Epoch 41/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6783 - loss: 0.5505 - val_accuracy: 0.5706 - val_loss: 0.6367\n",
            "Epoch 42/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6692 - loss: 0.5577 - val_accuracy: 0.5951 - val_loss: 0.5876\n",
            "Epoch 43/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6681 - loss: 0.5550 - val_accuracy: 0.5970 - val_loss: 0.6301\n",
            "Epoch 44/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6814 - loss: 0.5455 - val_accuracy: 0.6008 - val_loss: 0.5878\n",
            "Epoch 45/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6993 - loss: 0.5342 - val_accuracy: 0.5932 - val_loss: 0.6215\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\n",
            "ROC-AUC: 0.7475525482291966\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8723    0.4073    0.5553       302\n",
            "           1     0.5422    0.9217    0.6828       230\n",
            "\n",
            "    accuracy                         0.6297       532\n",
            "   macro avg     0.7073    0.6645    0.6190       532\n",
            "weighted avg     0.7296    0.6297    0.6104       532\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "#  Notebook - Naruto+ (KOI) - Expérience 2 seule\n",
        "# ============================================\n",
        "\n",
        "!pip install scikit-learn matplotlib seaborn pandas -q\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Monter Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Charger dataset\n",
        "DATASET_DIR = Path(\"/content/drive/MyDrive/data_KOI/astronet_dataset\")\n",
        "\n",
        "X_global = np.load(DATASET_DIR / \"X_global.npy\")\n",
        "X_local = np.load(DATASET_DIR / \"X_local.npy\")\n",
        "y = np.load(DATASET_DIR / \"y.npy\")\n",
        "\n",
        "print(\"Avant filtrage:\", np.unique(y, return_counts=True))\n",
        "\n",
        "# --- Filtrage Confirmed (2) et FP (0)\n",
        "mask = np.isin(y, [0, 2])\n",
        "X_global, X_local, y = X_global[mask], X_local[mask], y[mask]\n",
        "y = np.where(y == 2, 1, 0)\n",
        "\n",
        "print(\"Après filtrage:\", dict(zip(*np.unique(y, return_counts=True))))\n",
        "print(\"Global:\", X_global.shape, \" Local:\", X_local.shape, \" Labels:\", y.shape)\n",
        "\n",
        "# --- Split stratifié\n",
        "Xg_train, Xg_tmp, Xl_train, Xl_tmp, y_train, y_tmp = train_test_split(\n",
        "    X_global, X_local, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "Xg_val, Xg_test, Xl_val, Xl_test, y_val, y_test = train_test_split(\n",
        "    Xg_tmp, Xl_tmp, y_tmp, test_size=0.5, random_state=42, stratify=y_tmp\n",
        ")\n",
        "\n",
        "print(\"Train:\", Xg_train.shape, \" Val:\", Xg_val.shape, \" Test:\", Xg_test.shape)\n",
        "\n",
        "\n",
        "# --- Générateur équilibré\n",
        "def balanced_generator(Xg, Xl, y, batch_size=128):\n",
        "    pos_idx = np.where(y == 1)[0]\n",
        "    neg_idx = np.where(y == 0)[0]\n",
        "    while True:\n",
        "        idx_pos = np.random.choice(pos_idx, batch_size // 2, replace=True)\n",
        "        idx_neg = np.random.choice(neg_idx, batch_size // 2, replace=True)\n",
        "        idx = np.concatenate([idx_pos, idx_neg])\n",
        "        np.random.shuffle(idx)\n",
        "        yield {\"input_global\": Xg[idx], \"input_local\": Xl[idx]}, y[idx]\n",
        "\n",
        "\n",
        "# --- Naruto+ configurable\n",
        "def build_naruto(input_global_shape, input_local_shape,\n",
        "                 conv_filters=[64,128,256,512],\n",
        "                 dense_units=1024,\n",
        "                 dropout_rate=0.5,\n",
        "                 n_classes=2):\n",
        "\n",
        "    # Global branch\n",
        "    inp_global = tf.keras.Input(shape=input_global_shape, name=\"input_global\")\n",
        "    xg = inp_global\n",
        "    for f in conv_filters:\n",
        "        xg = tf.keras.layers.Conv1D(f, 5, activation=\"relu\", padding=\"same\")(xg)\n",
        "        xg = tf.keras.layers.BatchNormalization()(xg)\n",
        "        xg = tf.keras.layers.MaxPooling1D(3)(xg)\n",
        "    xg = tf.keras.layers.GlobalMaxPooling1D()(xg)\n",
        "\n",
        "    # Local branch\n",
        "    inp_local = tf.keras.Input(shape=input_local_shape, name=\"input_local\")\n",
        "    xl = tf.keras.layers.Conv1D(32, 5, activation=\"relu\", padding=\"same\")(inp_local)\n",
        "    xl = tf.keras.layers.BatchNormalization()(xl)\n",
        "    xl = tf.keras.layers.MaxPooling1D(2)(xl)\n",
        "    xl = tf.keras.layers.Conv1D(64, 5, activation=\"relu\", padding=\"same\")(xl)\n",
        "    xl = tf.keras.layers.BatchNormalization()(xl)\n",
        "    xl = tf.keras.layers.GlobalMaxPooling1D()(xl)\n",
        "\n",
        "    # Fusion\n",
        "    merged = tf.keras.layers.concatenate([xg, xl])\n",
        "    dense = tf.keras.layers.Dense(dense_units, activation=\"relu\")(merged)\n",
        "    dense = tf.keras.layers.Dropout(dropout_rate)(dense)\n",
        "    out = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(dense)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inp_global, inp_local], outputs=out)\n",
        "\n",
        "\n",
        "# --- Paramètres Expérience 2\n",
        "params = {\n",
        "    \"batch_size\": 128,\n",
        "    \"lr\": 5e-5,\n",
        "    \"dense_units\": 1024,\n",
        "    \"dropout_rate\": 0.5,\n",
        "    \"conv_filters\": [64,128,256,512],\n",
        "    \"loss\": \"sce\",\n",
        "    \"scheduler\": \"cosine\"\n",
        "}\n",
        "\n",
        "# --- Entraînement\n",
        "def train_and_eval(params):\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    model = build_naruto(\n",
        "        X_global.shape[1:], X_local.shape[1:],\n",
        "        conv_filters=params[\"conv_filters\"],\n",
        "        dense_units=params[\"dense_units\"],\n",
        "        dropout_rate=params[\"dropout_rate\"]\n",
        "    )\n",
        "\n",
        "    # Scheduler / LR\n",
        "    steps_per_epoch = max(1, len(y_train)//params[\"batch_size\"])\n",
        "    lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
        "        initial_learning_rate=params[\"lr\"],\n",
        "        first_decay_steps=steps_per_epoch*5,\n",
        "        t_mul=2.0,\n",
        "        m_mul=0.9,\n",
        "        alpha=1e-6\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "\n",
        "    # Callbacks\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "    checkpoint_path = \"/content/drive/MyDrive/models/naruto_KOI_best.keras\"\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)\n",
        "\n",
        "    steps_per_epoch = len(y_train)//params[\"batch_size\"]\n",
        "\n",
        "    history = model.fit(\n",
        "        balanced_generator(Xg_train, Xl_train, y_train, batch_size=params[\"batch_size\"]),\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_data=({\"input_global\": Xg_val, \"input_local\": Xl_val}, y_val),\n",
        "        epochs=50,\n",
        "        callbacks=[early_stop, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Recharger le meilleur modèle\n",
        "    best_model = tf.keras.models.load_model(checkpoint_path)\n",
        "\n",
        "    # --- Évaluation\n",
        "    y_pred = np.argmax(best_model.predict({\"input_global\": Xg_test, \"input_local\": Xl_test}), axis=1)\n",
        "    y_proba = best_model.predict({\"input_global\": Xg_test, \"input_local\": Xl_test})[:,1]\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "    print(\"\\nROC-AUC:\", auc)\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    return best_model, history\n",
        "\n",
        "# --- Lancer Expérience 2\n",
        "best_model, history = train_and_eval(params)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Inférence avec le modèle sauvegardé ---\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Charger le modèle entraîné\n",
        "model_path = \"/content/drive/MyDrive/models/naruto_KOI_best.keras\"\n",
        "inference_model = load_model(model_path)\n",
        "print(f\"✅ Modèle chargé depuis: {model_path}\")\n",
        "\n",
        "# Prédictions sur le jeu de test\n",
        "y_pred = np.argmax(inference_model.predict({\"input_global\": Xg_test, \"input_local\": Xl_test}), axis=1)\n",
        "y_proba = inference_model.predict({\"input_global\": Xg_test, \"input_local\": Xl_test})[:,1]\n",
        "\n",
        "# Évaluation\n",
        "auc = roc_auc_score(y_test, y_proba)\n",
        "print(\"\\nROC-AUC (inférence):\", auc)\n",
        "print(\"\\nClassification Report (inférence):\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# Exemple sur un seul échantillon\n",
        "sample_idx = 42\n",
        "xg_sample = Xg_test[sample_idx:sample_idx+1]\n",
        "xl_sample = Xl_test[sample_idx:sample_idx+1]\n",
        "proba = inference_model.predict({\"input_global\": xg_sample, \"input_local\": xl_sample})[0]\n",
        "print(f\"\\nÉchantillon {sample_idx} → Proba FP={proba[0]:.3f}, Confirmed={proba[1]:.3f}, Prédiction={np.argmax(proba)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXl_GLieZ3CR",
        "outputId": "e1e72a7f-4293-4faf-95a9-ea156f66efb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modèle chargé depuis: /content/drive/MyDrive/models/naruto_KOI_best.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\n",
            "ROC-AUC (inférence): 0.7475525482291966\n",
            "\n",
            "Classification Report (inférence):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8723    0.4073    0.5553       302\n",
            "           1     0.5422    0.9217    0.6828       230\n",
            "\n",
            "    accuracy                         0.6297       532\n",
            "   macro avg     0.7073    0.6645    0.6190       532\n",
            "weighted avg     0.7296    0.6297    0.6104       532\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n",
            "\n",
            "Échantillon 42 → Proba FP=0.408, Confirmed=0.592, Prédiction=1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
